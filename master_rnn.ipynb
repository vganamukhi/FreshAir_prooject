{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "master_rnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooiV_TBFJrmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import keras\n",
        "import boto3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from datetime import timedelta\n",
        "from dateutil import parser\n",
        "import boto3\n",
        "import urllib.request\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSY3w2nkJrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### reading in files\n",
        "\n",
        "\n",
        "dbfile = open('/content/drive/My Drive/Fresh_air_data/x_master_new.pkl', 'rb')      \n",
        "X = pkl.load(dbfile)\n",
        "dbfile.close() \n",
        "\n",
        "dbfile = open('/content/drive/My Drive/Fresh_air_data/y_master_new.pkl', 'rb')      \n",
        "Y = pkl.load(dbfile)\n",
        "dbfile.close() \n",
        "\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTLQ8lV_JrmV",
        "colab_type": "text"
      },
      "source": [
        "## Review Label to Words \n",
        "    * 1:'Smoking induced',\n",
        "    * 2:'Smoking induced',\n",
        "    * 3:'Smoking induced',\n",
        "    * 10:'Inconclusive',\n",
        "    * 11:'Inconclusive',\n",
        "    * 13:'Inconclusive',\n",
        "    * 20:'Environmental Anomalies',\n",
        "    * 30:'Environmental Anomalies',\n",
        "    * 31:'Environmental Anomalies',\n",
        "    * 32:'Environmental Anomalies',\n",
        "    * 33:'Environmental Anomalies',\n",
        "    * 34:'Environmental Anomalies',\n",
        "    * 35:'Environmental Anomalies',\n",
        "    * 36:'Environmental Anomalies',\n",
        "    * 45:'Environmental Anomalies',\n",
        "    * 50:'Environmental Anomalies', \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f6hEXR2JrmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "####### just smoking and Evironment  Variables ########\n",
        "\n",
        "x_bin=[]\n",
        "y_bin=[]\n",
        "smoking_event=0\n",
        "non_smoking_event=0\n",
        "\n",
        "\n",
        "for i, y in enumerate(Y):\n",
        "    if y in [1,2,3,31,32,33,34,35,36,45,50]:\n",
        "      if X[i].shape == (760, 4):\n",
        "        if y in [1,2,3]:\n",
        "          y_bin.append(1)\n",
        "          x_bin.append(X[i])\n",
        "          smoking_event+=1\n",
        "        elif y in [31,32,33,34,35,36,45,50]:\n",
        "          y_bin.append(0)\n",
        "          x_bin.append(X[i])\n",
        "          non_smoking_event+=1\n",
        "        \n",
        "    # if i==500 :break\n",
        "\n",
        "x_bin=np.array(x_bin)\n",
        "y_bin=np.array(y_bin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS5dJ8eSox-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(non_smoking_event)\n",
        "print(smoking_event)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOYdyip8ofVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "now=datetime.datetime.now"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NutwSIckpnN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyneDALXZRc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "# from keras.layers import SpatialDropout2D, Conv2D,ConvLSTM2D,CuDNNLSTM,Flatten\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akfcwsI2Jrme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### reading in file #########\n",
        "\n",
        "#### part two Creating \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense  \n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SpatialDropout2D, Conv2D,ConvLSTM2D, CuDNNLSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "\n",
        "BatchSize=32\n",
        "Epochs=1000\n",
        "responce_y=y_bin\n",
        "responce_x=x_bin\n",
        "\n",
        "################# call backs #########################\n",
        "checkpoint=ModelCheckpoint( \"/content/drive/My Drive/Fresh_air_data/models/model-{epoch:02d}-{val_binary_accuracy:.4f}.hdf5\"\n",
        ", monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1\n",
        ")\n",
        "\n",
        "tesnor_board=TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=BatchSize, write_graph=True, \n",
        "                         write_grads=True, embeddings_freq=0, embeddings_layer_names=None, \n",
        "                        embeddings_metadata=None, embeddings_data=None, update_freq='batch')\n",
        "\n",
        "early_stop=EarlyStopping(\n",
        "monitor='val_loss', min_delta=.0001, patience=2, verbose=0, mode='auto', baseline=None, restore_best_weights=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "################# Building the Model ########################\n",
        "# Initializing the RNN\n",
        "model = Sequential()\n",
        "\n",
        "# first Lstm Layer\n",
        "model.add(CuDNNLSTM(units = 50, return_sequences=True, input_shape=(responce_x.shape[1], responce_x.shape[2])))\n",
        "model.add(Dropout(.1)) #### .2 is the hueristic\n",
        "\n",
        "# # second Lstm Layer\n",
        "model.add(CuDNNLSTM(units = 25, return_sequences=False))\n",
        "model.add(Dropout(.1)) #### .2 is the hueristic\n",
        "\n",
        "# # #third Lstm Layer\n",
        "# model.add(LSTM(units = 50, return_sequences=True))\n",
        "# # model.add(Dropout(.1)) #### .2 is the hueristic\n",
        "\n",
        "# fouth Lstm Layer\n",
        "# model.add(LSTM(units = 50, return_sequences=False))\n",
        "# model.add(Dropout(.1)) #### .2 is the hueristic\n",
        "\n",
        "model.add(Dense(units=10, activation='relu'))\n",
        "### adding in the output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "### compile\n",
        "model.compile(optimizer='adam', loss = 'binary_crossentropy',metrics=['accuracy','binary_accuracy'])  #### RMSprop or Adam is recomended for RNN\n",
        "\n",
        "# fiting the RNN to the Trainging Set\n",
        "hist=model.fit(responce_x, responce_y, epochs=Epochs, batch_size=BatchSize,\n",
        "            validation_split=.1, use_multiprocessing=True, callbacks=[checkpoint,tesnor_board])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxkapoHow6Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=now()\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVsKi5KyN-kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### reading in file #########\n",
        "\n",
        "#### part two Creating \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense  \n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "\n",
        "BatchSize=32\n",
        "Epochs=1000\n",
        "responce_y=y_bin\n",
        "responce_x=x_bin\n",
        "\n",
        "################# call backs #########################\n",
        "checkpoint=ModelCheckpoint( \"/content/drive/My Drive/Fresh_air_data/models/model-{epoch:02d}-{val_binary_accuracy:.4f}.hdf5\"\n",
        ", monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1\n",
        ")\n",
        "\n",
        "tesnor_board=TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=BatchSize, write_graph=True, \n",
        "                         write_grads=True, embeddings_freq=0, embeddings_layer_names=None, \n",
        "                        embeddings_metadata=None, embeddings_data=None, update_freq='batch')\n",
        "\n",
        "early_stop=EarlyStopping(\n",
        "monitor='val_loss', min_delta=.0001, patience=2, verbose=0, mode='auto', baseline=None, restore_best_weights=False\n",
        ")\n",
        "\n",
        "import tensorflow as tf\n",
        "new_model = tf.keras.models.load_model('/content/drive/My Drive/Fresh_air_data/models/model-01-0.7197.hdf5')\n",
        "\n",
        "new_model.fit(responce_x, responce_y, epochs=Epochs, batch_size=BatchSize,\n",
        "            validation_split=.1, use_multiprocessing=True, callbacks=[checkpoint,tesnor_board])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEKjnpIgeXa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############ clearing out old data\n",
        "# if tf.gfile.Exists('logs'):\n",
        "#    tf.gfile.DeleteRecursively('logs') \n",
        "\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}